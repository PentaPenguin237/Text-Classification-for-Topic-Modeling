# Text Classification for Topic Modeling

This repository contains the complete Python script and resources for the "Text Classification for Topic Modeling" project, developed by me Guglielmo Luraschi Sicca - M.n. 92125339 as part of the DLBAIPNLP01 course at IU International University of Applied Sciences.

The project focuses on building a supervised machine learning pipeline to classify documents from the 20 Newsgroups dataset into their respective topics.

---

## Features

- **Data Preprocessing:** A pipeline that cleans text by lowercasing, removing punctuation and numbers, filtering stop words, and performing lemmatization.
- **Feature Engineering:** Utilizes TF-IDF vectorization with bigrams and trigrams to capture meaningful phrases.
- **Model Training:** Implements a Multinomial Naive Bayes (MNB) classifier, a strong baseline for text classification tasks.
- **Evaluation:** Provides a detailed classification report with metrics like precision, recall, and F1-score.
- **Visualization:** Generates a confusion matrix and bar charts showing the most predictive n-grams for each category, offering deep insights into the model's performance and decision-making process.

---

## Setup and Installation

To run this project, you will need Python 3 installed, along with some scientific computing libraries (as listed in the requirements.txt). Note: the following command are to be executed in Linux or in the git shell/bash/command line.

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/PentaPenguin237/Text-Classification-for-Topic-Modeling.git](https://github.com/PentaPenguin237/Text-Classification-for-Topic-Modeling.git)
    cd Text-Classification-for-Topic-Modeling
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install the required libraries:**
    A `requirements.txt` file is included for easy installation.
    ```bash
    pip install -r requirements.txt
    ```

---

## How to Run

Simply execute the main Python script from your terminal:

```bash
python main.py
```

The script will automatically:
1.  Download the necessary NLTK data (stopwords, wordnet).
2.  Fetch the 20 Newsgroups dataset from scikit-learn.
3.  Preprocess the data and train the classifier.
4.  Print the classification report to the console.
5.  Display the confusion matrix and top n-gram plots in separate windows.

---

## Results

The model achieves an overall accuracy of **81%** on the test set. The visualizations generated by the script provide a detailed breakdown of its performance, highlighting both its strengths in distinguishing unique topics and its challenges with closely related ones.

---

## License

This project is licensed under the MIT License. See the `LICENSE` file for more details.
